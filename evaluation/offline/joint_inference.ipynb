{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48040a4e-4bf2-4f8b-977a-907ab9397de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to allow importing of physicsnemo\n",
    "import sys\n",
    "sys.path.append(\"/global/u2/k/kfrields/climsim-kaggle-edition\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import os, gc\n",
    "from climsim_utils.data_utils import *\n",
    "from tqdm import tqdm\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "from physicsnemo.models.diffusion.preconditioning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bb7cd9-adeb-45df-a0e7-fb8875697bc7",
   "metadata": {},
   "source": [
    "## Load Deterministic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa1f8a28-b94f-4366-b57c-d73974c570a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_unet_path = '/pscratch/sd/k/kfrields/hugging/E3SM-MMF_saved_models/diffusion_models/diff_test/unet_model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab720d66-44f9-4784-8e90-44487abe4f17",
   "metadata": {},
   "source": [
    "## Set up Residual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "808bb21f-a368-4464-8bc9-9afda2cc2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edm_sampler(\n",
    "    net, latents, class_labels=None, randn_like=torch.randn_like,\n",
    "    num_steps=18, sigma_min=0.002, sigma_max=80, rho=7,\n",
    "    S_churn=0, S_min=0, S_max=float('inf'), S_noise=1,\n",
    "):\n",
    "    # Adjust noise levels based on what's supported by the network.\n",
    "    #sigma_min = max(sigma_min, net.sigma_min)\n",
    "    #sigma_max = min(sigma_max, net.sigma_max)\n",
    "\n",
    "    # Time step discretization.\n",
    "    step_indices = torch.arange(num_steps, dtype=torch.float64, device=latents.device)\n",
    "    t_steps = (sigma_max ** (1 / rho) + step_indices / (num_steps - 1) * (sigma_min ** (1 / rho) - sigma_max ** (1 / rho))) ** rho\n",
    "    t_steps = torch.cat([net.round_sigma(t_steps), torch.zeros_like(t_steps[:1])]) # t_N = 0\n",
    "\n",
    "    # Main sampling loop.\n",
    "    x_next = latents.to(torch.float64) * t_steps[0]\n",
    "    for i, (t_cur, t_next) in enumerate(zip(t_steps[:-1], t_steps[1:])): # 0, ..., N-1\n",
    "        x_cur = x_next\n",
    "\n",
    "        # Increase noise temporarily.\n",
    "        gamma = min(S_churn / num_steps, np.sqrt(2) - 1) if S_min <= t_cur <= S_max else 0\n",
    "        t_hat = net.round_sigma(t_cur + gamma * t_cur)\n",
    "        x_hat = x_cur + (t_hat ** 2 - t_cur ** 2).sqrt() * S_noise * randn_like(x_cur)\n",
    "\n",
    "        # Euler step.\n",
    "        denoised = net(x_hat, t_hat, class_labels).to(torch.float64)\n",
    "        d_cur = (x_hat - denoised) / t_hat\n",
    "        x_next = x_hat + (t_next - t_hat) * d_cur\n",
    "\n",
    "        # Apply 2nd order correction.\n",
    "        if i < num_steps - 1:\n",
    "            denoised = net(x_next, t_next, class_labels).to(torch.float64)\n",
    "            d_prime = (x_next - denoised) / t_next\n",
    "            x_next = x_hat + (t_next - t_hat) * (0.5 * d_cur + 0.5 * d_prime)\n",
    "\n",
    "    return x_next\n",
    "\n",
    "class StackedRandomGenerator:\n",
    "    def __init__(self, device, seeds):\n",
    "        super().__init__()\n",
    "        self.generators = [torch.Generator(device).manual_seed(int(seed) % (1 << 32)) for seed in seeds]\n",
    "\n",
    "    def randn(self, size, **kwargs):\n",
    "        assert size[0] == len(self.generators)\n",
    "        return torch.stack([torch.randn(size[1:], generator=gen, **kwargs) for gen in self.generators])\n",
    "\n",
    "    def randn_like(self, input):\n",
    "        return self.randn(input.shape, dtype=input.dtype, layout=input.layout, device=input.device)\n",
    "\n",
    "    def randint(self, *args, size, **kwargs):\n",
    "        assert size[0] == len(self.generators)\n",
    "        return torch.stack([torch.randint(*args, size=size[1:], generator=gen, **kwargs) for gen in self.generators])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff61eadd-8714-4d41-9999-e5984f96b2ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m latents \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m384\u001b[39m,\u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m64\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "latents = torch.randn(384,13, 64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c91e4e60-de94-4756-bdad-0cec0c7eeb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "latents = torch.randn(1,13, 64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8098051c-2c2e-47b3-9d4c-1dbc5b3c26cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EDMPrecond(\n",
       "  (model): DhariwalUNet(\n",
       "    (map_noise): PositionalEmbedding()\n",
       "    (map_layer0): Linear()\n",
       "    (map_layer1): Linear()\n",
       "    (enc): ModuleDict(\n",
       "      (60x60_conv): Conv1d()\n",
       "      (60x60_block0): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "      )\n",
       "      (60x60_block1): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "      )\n",
       "      (60x60_block2): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "      )\n",
       "      (30x30_down): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (30x30_block0): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (30x30_block1): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "      )\n",
       "      (30x30_block2): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "      )\n",
       "      (15x15_down): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (15x15_block0): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (15x15_block1): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "      )\n",
       "      (15x15_block2): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "      )\n",
       "      (7x7_down): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (7x7_block0): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (7x7_block1): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "      )\n",
       "      (7x7_block2): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "      )\n",
       "    )\n",
       "    (dec): ModuleDict(\n",
       "      (7x7_in0): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (attn): Attention(\n",
       "          (norm): GroupNorm()\n",
       "          (qkv): Conv1d()\n",
       "          (proj): Conv1d()\n",
       "        )\n",
       "      )\n",
       "      (7x7_in1): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "      )\n",
       "      (7x7_block0): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (7x7_block1): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (7x7_block2): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (7x7_block3): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (15x15_up): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (15x15_block0): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (15x15_block1): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (15x15_block2): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (15x15_block3): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (30x30_up): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (30x30_block0): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (30x30_block1): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (30x30_block2): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (30x30_block3): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (60x60_up): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (60x60_block0): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (60x60_block1): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (60x60_block2): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "      (60x60_block3): UNetBlock(\n",
       "        (norm0): GroupNorm()\n",
       "        (conv0): Conv1d()\n",
       "        (affine): Linear()\n",
       "        (norm1): GroupNorm()\n",
       "        (conv1): Conv1d()\n",
       "        (skip): Conv1d()\n",
       "      )\n",
       "    )\n",
       "    (out_norm): GroupNorm()\n",
       "    (out_conv): Conv1d()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_path = '/pscratch/sd/k/kfrields/hugging/E3SM-MMF_saved_models/diffusion_models/diff_test/diff_model.pt'\n",
    "#net = load_checkpoint(diff_path)\n",
    "diff_model = torch.load(diff_path)\n",
    "diff_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca64bce-31a6-429e-aad2-235dc2d03a7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = edm_sampler(diff_model, latents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8bfb8-f915-40e4-84db-9d5bd73e8d2b",
   "metadata": {},
   "source": [
    "## Set up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66e490e1-3b5c-42b6-aec4-0ac4925c8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_temperature_rules(T):\n",
    "    # Create an output tensor, initialized to zero\n",
    "    output = np.zeros_like(T)\n",
    "\n",
    "    # Apply the linear transition within the range 253.16 to 273.16\n",
    "    mask = (T >= 253.16) & (T <= 273.16)\n",
    "    output[mask] = (T[mask] - 253.16) / 20.0  # 20.0 is the range (273.16 - 253.16)\n",
    "\n",
    "    # Values where T > 273.16 set to 1\n",
    "    output[T > 273.16] = 1\n",
    "\n",
    "    # Values where T < 253.16 are already set to 0 by the initialization\n",
    "    return output\n",
    "\n",
    "\n",
    "def preprocessing_v2_rh_mc(data, input_path, target_path, input_sub, input_div, lbd_qn, out_scale):\n",
    "    npy_input = np.load(input_path)\n",
    "    npy_target = np.load(target_path)\n",
    "\n",
    "    surface_pressure = npy_input[:, data.ps_index]\n",
    "    \n",
    "    hyam_component = (data.hyam * data.p0)[np.newaxis,:]\n",
    "    hybm_component = data.hybm[np.newaxis,:] * surface_pressure[:, np.newaxis]\n",
    "    \n",
    "    pressures = hyam_component + hybm_component\n",
    "    pressures = pressures.reshape(-1,384,60)\n",
    "    \n",
    "    pressures_binned = data.zonal_bin_weight_3d(pressures)\n",
    "    \n",
    "    actual_input = npy_input.copy().reshape(-1, data.num_latlon, data.input_feature_len)\n",
    "\n",
    "    npy_input[:,120:180] = 1 - np.exp(-npy_input[:,120:180] * lbd_qn)\n",
    "    npy_input = (npy_input - input_sub)/input_div\n",
    "    npy_input = np.where(np.isnan(npy_input), 0, npy_input)\n",
    "    npy_input = np.where(np.isinf(npy_input), 0, npy_input)\n",
    "    npy_input[:,120:120+15] = 0\n",
    "    npy_input[:,60:120] = np.clip(npy_input[:,60:120], 0, 1.2)\n",
    "    torch_input = torch.tensor(npy_input).float()\n",
    "\n",
    "    reshaped_target = npy_target.reshape(-1, data.num_latlon, data.target_feature_len)\n",
    "\n",
    "    #print(reshaped_target.shape)\n",
    "    t_before = actual_input[:, :, 0:60]\n",
    "    qn_before = actual_input[:, :, 120:180]\n",
    "    liq_frac_before = apply_temperature_rules(t_before)\n",
    "    qc_before = liq_frac_before * qn_before\n",
    "    qi_before = (1 - liq_frac_before) * qn_before\n",
    "\n",
    "    t_new = t_before + reshaped_target[:, :, 0:60]*1200\n",
    "    qn_new = qn_before + reshaped_target[:, :, 120:180]*1200\n",
    "    liq_frac_new = apply_temperature_rules(t_new)\n",
    "    qc_new = liq_frac_new * qn_new\n",
    "    qi_new = (1 - liq_frac_new) * qn_new\n",
    "    print(qc_new.shape)\n",
    "    actual_target = np.concatenate((reshaped_target[:, :, 0:120], \n",
    "                                    (qc_new - qc_before)/1200, \n",
    "                                    (qi_new - qi_before)/1200, \n",
    "                                    reshaped_target[:, :, 180:240], \n",
    "                                    reshaped_target[:, :, 240:]), axis=2)\n",
    "    return torch_input, actual_input, actual_target, pressures_binned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bada5259-0f0d-4826-b5bd-857c3802cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_path = '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc/scoring_set/scoring_input.npy'\n",
    "#target_path = '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc/scoring_set/scoring_target.npy'\n",
    "\n",
    "#============creates normalization metrics========\n",
    "input_mean_v2_rh_mc_file = 'input_mean_v2_rh_mc_pervar.nc'\n",
    "input_max_v2_rh_mc_file = 'input_max_v2_rh_mc_pervar.nc'\n",
    "input_min_v2_rh_mc_file = 'input_min_v2_rh_mc_pervar.nc'\n",
    "output_scale_v2_rh_mc_file = 'output_scale_std_lowerthred_v2_rh_mc.nc'\n",
    "lbd_qn_file = 'qn_exp_lambda_large.txt'\n",
    "\n",
    "grid_path = '../../grid_info/ClimSim_low-res_grid-info.nc'\n",
    "\n",
    "grid_info = xr.open_dataset(grid_path)\n",
    "input_mean = xr.open_dataset('../../preprocessing/normalizations/inputs/' + input_mean_v2_rh_mc_file)\n",
    "input_max = xr.open_dataset('../../preprocessing/normalizations/inputs/' + input_max_v2_rh_mc_file)\n",
    "input_min = xr.open_dataset('../../preprocessing/normalizations/inputs/' + input_min_v2_rh_mc_file)\n",
    "output_scale = xr.open_dataset('../../preprocessing/normalizations/outputs/' + output_scale_v2_rh_mc_file)\n",
    "lbd_qn = np.loadtxt('../../preprocessing/normalizations/inputs/' + lbd_qn_file, delimiter = ',')\n",
    "\n",
    "data = data_utils(grid_info = grid_info, \n",
    "                  input_mean = input_mean, \n",
    "                  input_max = input_max, \n",
    "                  input_min = input_min, \n",
    "                  output_scale = output_scale,\n",
    "                  qinput_log = False,\n",
    "                  normalize = False)\n",
    "data.set_to_v2_rh_mc_vars()\n",
    "\n",
    "input_sub_v2_rh_mc, input_div_v2_rh_mc, out_scale_v2_rh_mc = data.save_norm(write=False) # this extracts only the relevant variables\n",
    "input_sub_v2_rh_mc = input_sub_v2_rh_mc[None, :]\n",
    "input_div_v2_rh_mc = input_div_v2_rh_mc[None, :]\n",
    "out_scale_v2_rh_mc = out_scale_v2_rh_mc[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3281c9b1-10a7-4d5d-aa8f-9d5601572cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_592544/1028368508.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  npy_input = (npy_input - input_sub)/input_div\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4380, 384, 60)\n"
     ]
    }
   ],
   "source": [
    "v2_rh_mc_input_path = '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc/test_set/test_input.npy'\n",
    "v2_rh_mc_target_path = '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc/test_set/test_target.npy'\n",
    "\n",
    "#applies preprocessing to scoring data\n",
    "torch_input_v2_rh_mc, actual_input_v2_rh_mc, actual_target, pressures_binned = preprocessing_v2_rh_mc(data = data, \n",
    "                                                                                                      input_path = v2_rh_mc_input_path, \n",
    "                                                                                                      target_path = v2_rh_mc_target_path, \n",
    "                                                                                                      input_sub = input_sub_v2_rh_mc, \n",
    "                                                                                                      input_div = input_div_v2_rh_mc, \n",
    "                                                                                                      lbd_qn = lbd_qn, \n",
    "                                                                                                      out_scale = out_scale_v2_rh_mc)\n",
    "\n",
    "standard_save_path = '/pscratch/sd/k/kfrields/hugging/E3SM-MMF_saved_models/diffusion_models/diff_test/offline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d49a253-4401-4eb9-9681-6f2921a06068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_joint_model(data, deterministic_model_path, res_model_path, actual_input, torch_input, out_scale):\n",
    "    #Load deterministic model\n",
    "    deterministic_model = torch.jit.load(deterministic_model_path).to(device)\n",
    "    deterministic_model.eval()\n",
    "\n",
    "    #Load residual model\n",
    "    diff_model = torch.load(diff_path).to(device)\n",
    "    diff_model.eval()\n",
    "    \n",
    "    \n",
    "    batch_joint_list = []\n",
    "    batch_size = data.num_latlon\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, torch_input.shape[0], batch_size)):\n",
    "            batch = torch_input[i:i+batch_size].to(device)\n",
    "            batch_pred = deterministic_model(batch)\n",
    "\n",
    "            #prune output before feeding to deterministic model\n",
    "            batch_pred[:, 60:75] = 0\n",
    "            batch_pred[:, 120:135] = 0\n",
    "            batch_pred[:, 180:195] = 0\n",
    "            batch_pred[:, 240:255] = 0\n",
    "            \n",
    "            latents = torch.randn(1,13, 64).to(device)\n",
    "            res_pred = edm_sampler(diff_model, latents) #maybe have to remove the last 4 meaningless levels??\n",
    "            #fix this to automatically remove in res prediction ^^\n",
    "            \n",
    "            print(f'batch pred shape {batch_pred.shape}')\n",
    "            print(f'res pred shape {res_pred.shape}')\n",
    "\n",
    "            #move this to diffusion model later\n",
    "            x_profile = res_pred[:,:data.target_profile_num, :60]#maybe have to remove the last 4 meaningless levels??\n",
    "            #fix this to automatically remove in res prediction ^^\n",
    "            \n",
    "            x_scalar = res_pred[:,data.target_profile_num:, :60]\n",
    "\n",
    "            # reshape x_profile to (batch, input_profile_num, levels)\n",
    "            x_profile = x_profile.reshape(data.target_profile_num*60)\n",
    "            # broadcast x_scalar to (batch, input_scalar_num, levels)\n",
    "            x_scalar = x_scalar.unsqueeze(2).expand(-1, -1, 60)\n",
    "\n",
    "            #concatenate x_profile, x_scalar, x_loc to (batch, input_profile_num+input_scalar_num, levels)\n",
    "            x_res = torch.cat((x_profile, x_scalar), dim=1)\n",
    "\n",
    "            \n",
    "            joint_pred = batch_pred + x_res\n",
    "            \n",
    "            batch_joint_list.append(joint_pred.cpu().numpy() / out_scale)#outscaling only applied when inferencing or wrapping\n",
    "            \n",
    "    model_preds = np.stack(batch_joint_list, axis=0)\n",
    "    \n",
    "    #print(deterministic_model_preds.shape)\n",
    "    #for deterministic_pred in deterministic_model_preds:\n",
    "    #    print(deterministic_pred.shape)\n",
    "\n",
    "        \n",
    "\n",
    "    t_before = actual_input[:, :, 0:60]\n",
    "    qn_before = actual_input[:, :, 120:180]\n",
    "    liq_frac_before = apply_temperature_rules(t_before)\n",
    "    qc_before = liq_frac_before * qn_before\n",
    "    qi_before = (1 - liq_frac_before) * qn_before\n",
    "\n",
    "    t_new = t_before + model_preds[:, :, 0:60]*1200\n",
    "    qn_new = qn_before + model_preds[:, :, 120:180]*1200\n",
    "    liq_frac_new = apply_temperature_rules(t_new)\n",
    "    qc_new = liq_frac_new * qn_new\n",
    "    qi_new = (1 - liq_frac_new) * qn_new\n",
    "    \n",
    "    actual_preds = np.concatenate((model_preds[:, :, 0:120], \n",
    "                                  (qc_new - qc_before)/1200, \n",
    "                                  (qi_new - qi_before)/1200, \n",
    "                                   model_preds[:, :, 180:240], \n",
    "                                   model_preds[:, :, 240:]), axis=2)\n",
    "\n",
    "    del deterministic_model\n",
    "    del batch_pred_list\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return actual_preds\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f76e405-39a7-43df-b53f-e05486fe31d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch pred shape torch.Size([100, 308])\n",
      "res pred shape torch.Size([1, 13, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.cuda.DoubleTensor{[1, 8, 1, 60]}, size=[-1, -1, 60]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m standard_unet_preds \u001b[38;5;241m=\u001b[39m \u001b[43minference_joint_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mstandard_unet_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdiff_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mactual_input_v2_rh_mc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtorch_input_v2_rh_mc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mout_scale_v2_rh_mc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 40\u001b[0m, in \u001b[0;36minference_joint_model\u001b[0;34m(data, deterministic_model_path, res_model_path, actual_input, torch_input, out_scale)\u001b[0m\n\u001b[1;32m     38\u001b[0m x_profile \u001b[38;5;241m=\u001b[39m x_profile\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, data\u001b[38;5;241m.\u001b[39mtarget_profile_num, \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# broadcast x_scalar to (batch, input_scalar_num, levels)\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m x_scalar \u001b[38;5;241m=\u001b[39m \u001b[43mx_scalar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#concatenate x_profile, x_scalar, x_loc to (batch, input_profile_num+input_scalar_num, levels)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m x_res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x_profile, x_scalar), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.cuda.DoubleTensor{[1, 8, 1, 60]}, size=[-1, -1, 60]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)"
     ]
    }
   ],
   "source": [
    "standard_unet_preds = inference_joint_model(data,\n",
    "                                        standard_unet_path,\n",
    "                                        diff_path,\n",
    "                                        actual_input_v2_rh_mc[:100],\n",
    "                                        torch_input_v2_rh_mc[:100],\n",
    "                                        out_scale_v2_rh_mc[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc46ba38-7739-4a54-baff-7aa85313e252",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deterministic_model_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m deterministic_pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mdeterministic_model_preds\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;28mprint\u001b[39m(deterministic_pred\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'deterministic_model_preds' is not defined"
     ]
    }
   ],
   "source": [
    "for deterministic_pred in range(deterministic_model_preds.shape[0]):\n",
    "        print(deterministic_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c403f155-54e4-4a54-a64b-015be020466c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msample\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8801a202-411d-43c1-9e24-86c486840c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnvironment",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
